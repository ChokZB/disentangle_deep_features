# Disentangle Deep Features in Generative Convolution Network for Interpretable Neural-based Synthesis Applications

![License](https://img.shields.io/badge/License-MIT-blue)
![Python](https://img.shields.io/badge/Python-3.8+-yellow)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChokZB/disentangle_deep_features/blob/main/disentangle_deep_features.ipynb)

This project investigates how hierarchical deep features can be disentangled and interpreted within generative convolutional networks for image synthesis tasks.  

A modified neural style transfer (NST) framework was implemented using pretrained VGG19 (Caffe weights) to analyse the relationship between content, style, and latent representations across convolutional layers.

---

## ğŸ“š Overview

The aim is to explore interpretability in neural-based synthesis by:
- Disentangling feature hierarchies within VGG-based encoders.
- Studying how different layers encode content and style information.
- Visualising and analysing the latent spaces contributing to image generation.
- Comparing baseline and modified NST pipelines to evaluate synthesis interpretability.

---

## ğŸ“ Project Structure

```
disentangle_deep_features/
â”‚
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ Content_1.jpg                     # Sample content image
â”‚   â”œâ”€â”€ Style_1.jpg                       # Sample style image
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ download_models.sh                # Optional script to automatically fetch the VGG19 Caffe weights
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ Dual_Channel_NST/                 # Modified NST outputs
â”‚   â”œâ”€â”€ L-H_Frequency_Images/             # Frequency decomposition visualisations
â”‚   â”œâ”€â”€ Original_NST/                     # Baseline NST results
â”‚   â””â”€â”€ README.md                         # Notes describing generated output folders
â”‚
â”œâ”€â”€ .gitignore                            # Files/folders excluded from Git
â”‚
â”œâ”€â”€ LICENSE                               # MIT License
â”‚
â”œâ”€â”€ README.md                             # Project overview and instructions
â”‚
â”œâ”€â”€ disentangle_deep_features.ipynb       # Main implementation notebook
â”‚
â””â”€â”€ requirements.txt                      # Dependency list for reproducibility
```

---

## âš™ï¸ Tools & Frameworks

- **Python** â‰¥ 3.8  
- **PyTorch** â‰¥ 2.0  
- **NumPy**, **Matplotlib**, **OpenCV**
- **Google Colab / Jupyter Notebook** for experimentation and visualisation  

---

## ğŸš€ Setup & Execution

1. **Clone the repository**
   
   ```bash
   git clone https://github.com/ChokZB/disentangle_deep_features.git
   cd disentangle_deep_features
   ```

2. **Create a virtual environment**

   ```bash
   python -m venv venv
   source venv/bin/activate        # On Linux / macOS
   venv\Scripts\activate           # On Windows
   ```

3. **Install dependencies**
   
   Install all required Python packages using the provided `requirements.txt`:

   ```bash
   pip install -r requirements.txt
   ```

4. **Download pretrained model weights**
   
   The VGG19 weights used are the original Caffe-based parameters, available from:

   ```
   https://web.eecs.umich.edu/~justincj/models/vgg19-d01eb7cb.pth
   ```

   Place the file inside:

   ```
   models/vgg19-d01eb7cb.pth
   ```

5. **Run the notebook**

   ```bash
   jupyter notebook disentangle_deep_features.ipynb
   ```

   or open it directly in Google Colab.

---

## ğŸ§  Methodology

1. **Feature Extraction:**
   VGG19 pretrained weights (Caffe) used for hierarchical convolutional feature extraction.

2. **Feature Disentanglement:**
   Mid-level feature maps analysed and separated into content and style representations using frequency and channel-wise decomposition.

3. **Neural Style Transfer Pipeline:**
   Both baseline and dual-channel NST architectures implemented to compare interpretability and reconstruction fidelity.

4. **Feature Visualisation:**
   Layer-wise activations, Gram matrices, and reconstructed feature maps visualised to understand network interpretability.

---

## ğŸ“ˆ Results & Analysis

* Disentangled representations demonstrate improved interpretability across convolutional depth.
* Dual-channel NST architecture produced clearer content preservation and reduced feature interference.
* Frequency-based decomposition offered insight into the separation of structural and stylistic information.

Example outputs can be found in:

```
outputs/Dual_Channel_NST/
outputs/L-H_Frequency_Images/
outputs/Original_NST/
```

---


## ğŸ§‘â€ğŸ’» Author

**Chok Zu Bing**

GitHub: [@ChokZB](https://github.com/ChokZB)

---

## ğŸªª Licence

This project is released under the [MIT License](LICENSE).
